# Lezione 21
## Vettori Geometrici
### Vettori Applicati
Indiciamo con $\mathcal{A}^{1}$ la **retta euclidea** (con $\mathcal{A}^{2}$ e $\mathcal{A}^{3}$ il **piano** e lo **spazio euclide**o).
Fissando sulla retta $\mathcal{A}^{1}$ un punto $O$ e un'unità di misura, cioè un segmento $\overline{OA},$ otteniamo un'applicazione bigettiva fra i punti della retta e i numeri reali (infatti, ogni punto sulla retta corrisponde ad un numero reale). Ciò introduce su $\mathcal{A}^{1}$ una somma e un prodotto, che lo rendono un campo. È possibile ripetere questa costruzione nel piano e nello spazio?

Prendiamo per esempio il piano, $\mathcal{A}^{2}.$ Fissiamo un punto $O\in\mathcal{A}^{2}.$ Adesso ogni punto del piano (vale lo stesso ragionamento per lo spazio) può venire considerato non solamente per conto suo, ma anche in relazione al punto fissato $O.$
###### Definizione - Vettore Applicato
Si definisce **vettore applicato** in $O$ un segmento orientato con primo estremo il punto $O\in\mathcal{A}^{2}$ (o $\mathcal{A}^{3}$) e secondo estremo un altro punto $A\in\mathcal{A}^{2}.$ Questo vettore sarà disegnato come una freccia che parte da $O$ e giunge ad $A,$ e indicato con $\overrightarrow{OA}.$ 

L'insieme dei vettori applicati in $O$ sarà indicato con $\mathcal{V}_{O}^{2}$ ($\mathcal{V}_{O}^{3}$ nello spazio). Il punto $O$ viene chiamato **origine** di $\mathcal{V}_{O}^{2}.$ 

Si può definire una funzione bigettiva $\Phi_{O}:\mathcal{A}^{2}\longrightarrow\mathcal{V}_{0}^{2}$ ponendo $\Phi_{O}(A)=\overrightarrow{OA}$ per ogni $A\in\mathcal{A}^{2};$ al punto $A$ viene associato il vettore applicato in $O$ che termina in $A.$ ![[lez21vettoreOA.svg]] 
In particolare, all'origine $O$ si associa il vettore $\overrightarrow{OO},$ detto *vettore nullo*.
#### Somma tra vettori applicati
Presi due vettori applicati $\overrightarrow{OA}$ e $\overrightarrow{OB},$ la loro somma $\overrightarrow{OA}+\overrightarrow{OB}$ è il vettore applicato $\overrightarrow{OC},$ dove $C$ è il quarto vertice del parallelogramma individuato da $O,A$ e $B.$ Il punto $C$ è il secondo estremo del vettore applicato in $B$, parallelo, congruente e con lo stesso verso di $\overrightarrow{OA}.$ Quest'ultima caratterizzazione funziona anche quando $O,A$ e $B$ sono allineati.

|                                |                                     |
| ------------------------------ | ----------------------------------- |
| ![[lez21sommavettori.svg]]     | ![[lez21sommavettoriallineati.svg]] |
| Somma di vettori non allineati | Somma di vettori allineati          |
#### Prodotto di un vettore applicato per uno scalare
Se $\lambda\in\mathbb{R}$ e $\overrightarrow{OA}\in\mathcal{V}_{O}^{2},$ allora il prodotto di $\lambda$ per $\overrightarrow{OA}$ è il vettore $\overrightarrow{OC}=\lambda\overrightarrow{OA},$ dove $C$ è il punto sulla retta passante per $O$ e $A$ tale che il rapporto fra la lunghezza del segmento $\overrightarrow{OC}$ e quella del segmento $\overrightarrow{OA}$ sia esattamente $|\lambda|.$ $\lambda\overrightarrow{OA}$ ha la stessa direzione di $\overrightarrow{OA},$ lunghezza moltiplicata per $|\lambda|$ e verso uguale od opposto (a seconda del segno di $\lambda$).

|                                   |                                      |
| --------------------------------- | ------------------------------------ |
| ![150](lez21prodottovettscal.svg) | ![180](lez21prodottovettscalneg.svg) |
| Caso in cui $\lambda>0$           | Caso in cui $\lambda<0$              | 

## Spazi e Sottospazi
### Vettori e $\mathbb{R}^{n}$
Le soluzioni di un sistema lineare con $n$ incognite sono liste di $n$ numeri reali. Quei numeri, sostituiti nell'ordine alle incognite, soddisfano tutte le equazioni del sistema.

L'insieme delle liste di $n$ numeri reali viene indicato con $\mathbb{R}^n:$$$\mathbb{R}^{n}=\left\{v=\begin{vmatrix} v_{1}\\\vdots\\v_{n} \end{vmatrix},\Biggr| v_{1},...,v_{n}\in\mathbb{R}\right\}.$$
L'insieme $\mathbb{R}^n$ può essere considerato come un piano geometrico $n$-dimensionale, in cui ogni punto è rappresentato attraverso la $n$-upla di numeri reali. Gli elementi di questo insieme prendono il nome di **vettori**.
#### Operazioni tra vettori
##### Somma
La somma di due vettori di $\mathbb{R}^n$ è semplicemente la somma componente per componente:$$\forall v=\begin{vmatrix} v_{1}\\\vdots\\ v_{n}\end{vmatrix}\in \mathbb{R}^{n}\quad\forall w=\begin{vmatrix} w_{1}\\\vdots\\w_{n}\end{vmatrix}\in \mathbb{R}^{n}\longrightarrow v+w=\begin{vmatrix} v_{1}\\\vdots\\ v_{n}\end{vmatrix}+\begin{vmatrix} w_{1}\\\vdots\\w_{n}\end{vmatrix}=\begin{vmatrix} v_{1}+w_{1}\\\vdots\\v_{n}+w_{n}\end{vmatrix}$$
##### Prodotto per uno scalare
Il prodotto di un vettore per un numero reale (che viene definito **scalare**)  è definito componente per componente: $$\forall\lambda\in\mathbb{R},=\begin{vmatrix} v_{1}\\\vdots\\ v_{n}\end{vmatrix}\in \mathbb{R}^{n}\longrightarrow \lambda v=\lambda\begin{vmatrix} v_{1}\\\vdots\\ v_{n}\end{vmatrix}=\begin{vmatrix} \lambda v_{1}\\\vdots\\\lambda v_{n}\end{vmatrix};$$
##### $\mathbb{R}^n$ come gruppo commutativo
$\mathbb{R}^n$ è un gruppo commutativo rispetto alla somma, ed il suo elemento neutro è il **vettore nullo**:$$O=\begin{vmatrix}0\\\vdots\\0\end{vmatrix}$$ e l'opposto di un vettore è $$-\begin{vmatrix} v_{1}\\ \vdots\\ v_n \end{vmatrix}=\begin{vmatrix} -v_{1}\\ \vdots\\ -v_n \end{vmatrix}.$$
Il prodotto per scalari invece soddisfa le seguenti proprietà:
1) $\forall\lambda\in\mathbb{R}\quad$$\forall v,w\in\mathbb{R}^{n}\quad$$\lambda(v+w)=\lambda v+\lambda w;$
2) $\forall\lambda,\mu\in\mathbb{R}^{n}\quad$$\forall v\in\mathbb{R}^{n}\quad$$(\lambda+\mu)v=\lambda v+\mu v;$
3) $\forall \lambda,\mu\in\mathbb{R}\quad$$\forall v\in\mathbb{R}^{n}$$(\lambda\mu)v=\lambda(\mu v);$
4) $\forall v\in\mathbb{R}^{n}\quad$$1v=v$ e $0v=O$ 
### Spazio Vettoriale
Uno **spazio vettoriale** (detto anche spazio *lineare*) su $\mathbb{R}$ è un insieme $V$ su cui sono definite due operazioni: una *somma*  (che a due elementi di $V$ associa un elemento di $V$) e un prodotto per scalari (che ad un elemento di $\mathbb{R}$ e un elemento di $V$ associa un elemento di $V$) che soddisfa le seguenti proprietà:
1) È chiuso rispetto all'operazione di somma.
2) È chiuso rispetto all'operazione di prodotto di un vettore per uno scalare.
3) $\forall u, v, w \in V: (u + v) + w = u + (v + w)$ (associatività della somma);
4) $\exists O\in V |\forall v \in V: v + O = O + v = v$ (esiste l'elemento neutro per la somma);
5) $\forall v \in V\ \exists-v\in V: v + (-v) = (-v) + v = 0$ (esiste l'opposto per la somma);
6) $\forall v, w \in V: v + w = w + v$ (commutatività della somma);
7) $\begin{rcases}\forall \lambda \in \mathbb{R}, \forall v, w \in V: \lambda(v + w) = \lambda v + \lambda w; \\ \forall \lambda, \mu \in \mathbb{R}, \forall v, w \in V: (\lambda + \mu) v = \lambda v + \mu v;\end{rcases}$ (distributività del prodotto per scalari);
8) $\forall \lambda, \mu \in \mathbb{R}, \forall v \in V: (\lambda \mu) v = \lambda (\mu v)$ (associatività del prodotto per scalari);
9) $\forall v\in V: 1v=v$ e $0v=O.$

$V$ con la somma è un gruppo commutativo. Inoltre, se al posto di $\mathbb{R}$ sostituiamo ovunque un altro campo $\mathbb{K}$ abbiamo la definizione di spazio vettoriale sul campo $\mathbb{K}.$
###### Proposizione: $\mathcal{V}_{O}^2$ è uno spazio vettoriale
Per dimostrare che l'insieme dei vettori applicati in $O$ nel piano $V_{O}^{2}$ è uno spazio vettoriale (vale la stessa dimostrazione per $\mathcal{V}_O^3$), dobbiamo verificare che soddisfi tutte le otto proprietà degli spazi vettoriali:
1. **Chiusura rispetto all'addizione**: Se $v = (v_1, v_2)$ e $w = (w_1, w_2)$ sono vettori in $\mathcal{V}_{O}^{2}$, allora la loro somma $v + w = (v_1 + w_1, v_2 + w_2)$ è anch'essa in $\mathcal{V}_{O}^{2}$.
2. **Commutatività dell'addizione**: Per ogni coppia di vettori $v$ e $w$ in $\mathcal{V}_{O}^{2}$, vale la proprietà $v + w = w + v$.
3. **Associatività dell'addizione**: Per ogni tripletta di vettori $u$, $v$, e $w$ in $\mathcal{V}_{O}^{2}$, vale la proprietà $(u + v) + w = u + (v + w)$.
4. **Esistenza dell'elemento neutro dell'addizione**: Il vettore $O = (0, 0)$ in $\mathcal{V}_{O}^{2}$ è l'elemento neutro dell'addizione, perché per ogni vettore $v = (v_1, v_2)$ in $\mathcal{V}_{O}^{2}$, vale la proprietà $v + 0 = v$.
5. **Esistenza dell'opposto additivo**: Per ogni vettore $v = (v_1, v_2)$ in $\mathcal{V}_{O}^{2}$, esiste un vettore $-v = (-v_1, -v_2)$ in $\mathcal{V}_{O}^{2}$ tale che $v + (-v) = 0$.
6. **Chiusura rispetto alla moltiplicazione per scalari**: Se $v = (v_1, v_2)$ è un vettore in $\mathcal{V}_{O}^{2}$ e $c$ è uno scalare, allora il prodotto $cv = (cv_1, cv_2)$ è anch'esso in $\mathcal{V}_{O}^{2}$.
7. **Associatività della moltiplicazione per scalari**: Per ogni vettore $v = (v_1, v_2)$ in $\mathcal{V}_{O}^{2}$ e scalari $a$ e $b$, vale la proprietà $a(bv) = (abv_1, abv_2) = (ab)v$.
8. **Distributività della moltiplicazione per scalari rispetto all'addizione di vettori e scalari**: Per ogni coppia di vettori $u = (u_1, u_2)$ e $v = (v_1, v_2)$ in $\mathcal{V}_{O}^{2}$ e scalare $a$, valgono le proprietà $a(u + v) = a(u_1 + v_1, u_2 + v_2) = (au_1 + av_1, au_2 + av_2) = au + av$ e $(a + b)v = (a + b)(v_1, v_2) = (av_1 + bv_1, av_2 + bv_2) = av + bv$.

Quindi, $\mathcal{V}_{O}^{2}$ soddisfa tutte le otto proprietà degli spazi vettoriali, e quindi è uno spazio vettoriale.
###### Proposizione: l'insieme $M_{(m,n)}(\mathbb{R})$ delle matrici $n\times m$ è uno spazio vettoriale
L'insieme delle matrici $n\times m,$ denotato con $M_{(m,n)}(\mathbb{R})$ è uno spazio vettoriale, con le operazioni: $$\begin{vmatrix} a_{11}&...&a_{1n} \\ \vdots&\ddots&\vdots \\a_{m1}&...&a_{mn}\end{vmatrix}+\begin{vmatrix} b_{11}&...&b_{1n} \\ \vdots&\ddots&\vdots \\ b_{m1}&...&b_{mn}\end{vmatrix} = \begin{vmatrix} a_{11}+b_{11}&...&a_{1n}+b_{1n} \\ \vdots&\ddots&\vdots \\a_{m1}+b_{m1}&...&a_{mn}+b_{mn}\end{vmatrix},$$$$\lambda\begin{vmatrix}a_{11}&...&a_{1n} \\ \vdots&\ddots&\vdots \\a_{m1}&...&a_{mn} \end{vmatrix} = \begin{vmatrix} \lambda a_{11}&...&\lambda a_{1n} \\ \vdots&\ddots&\vdots \\\lambda a_{m1}&...&\lambda a_{mn}\end{vmatrix}.$$
### Sottospazio Vettoriale
Un sottospazio vettoriale di uno spazio vettoriale $V$ è un sottoinsieme $W\subseteq V$ chiuso rispetto alla domma e al prodotto per scalari, cioè tale che $$\forall w,w_{1},w_{2}\in W\quad\lambda\in\mathbb{R}\qquad w_{1}+w_{2}\quad e\quad \lambda w\in W.$$Il vettore nullo $O$ è contenuto in qualunque sottospazio vettoriale $W$: infatti, se $w$ è un qualunque elemento di $W,$ allora $O=0w\in W.$ In particolare, un sottoinsieme di uno spazio vettoriale che non contiene il vettore nullo non può essere un sottospazio vettoriale. Analogamente, se $v\in W$ allora $-v=(-1)v\in W,$ per cui un sottospazio vettoriale contiene anche l'opposto di ogni suo elemento.

Quindi, un sottospazio per essere tale deve soddisfare tre requisiti:
1) Deve contenere il vettore nullo $O$
2) Deve essere chiuso rispetto alla somma
3) Deve essere chiuso rispetto al prodotto

In sintesi, un sottospazio vettoriale è uno spazio vettoriale che è contenuto in uno spazio vettoriale più grande.

###### Proposizione - Le soluzioni di un sistema lineare omogeneo costituiscono un sottospazio vettoriale di $\mathbb{R}^n$
Per dimostrare che le soluzioni di un sistema lineare omogeneo costituiscono un sottospazio vettoriale di $\mathbb{R}^n$, dobbiamo verificare tre proprietà fondamentali dei sottospazi vettoriali:

1. **Chiusura rispetto all'addizione**: Se $x$ e $y$ sono soluzioni del sistema, allora anche $x + y$ deve essere una soluzione. Questo è vero perché se $Ax = \mathbf{0}$ e $Ay = 0$, allora $A(x + y) = Ax + Ay = 0$.
2. **Chiusura rispetto alla moltiplicazione per scalari**: Se $x$ è una soluzione del sistema e $c$ è uno scalare, allora anche $c\mathbf{x}$ deve essere una soluzione. Questo è vero perché se $Ax=0$, allora $A(cx) = cAx = c\cdot0= 0$.
3. **Contiene il vettore nullo**: Il sistema omogeneo ha sempre la soluzione $x = \mathbf{0}$, poiché $A0 = 0$.

Quindi, le soluzioni di un sistema lineare omogeneo formano un sottospazio vettoriale di $\mathbb{R}^n$.
### Definizione Rigorosa
#### Spazio Vettoriale
Fissiamo un punto $O$ e $V=\{$insieme dei segmenti orientati con il primo estremo centrato in $O\},$ ovvero l'insieme dei vettori applicati in $O.$ Introduciamo un'operazione in $V$: la somma tra due vettori, ovvero un segmento che unisce $O$ al quarto vertice del parallelogramma individuato da $\overrightarrow{OA}$ e $\overrightarrow{OB}.$ 
Detto formalmente: prendo $\overrightarrow{OA}$ e considero il segmento centrato in $A$ della stessa lunghezza, direzione e verso di $\overrightarrow{OB}$ (con origine $A$ e non $O$). Il segmento risultante è il segmento $\overrightarrow{OC}.$ ![[lez21sommavettori.svg]]

Con questa operazione e con elemento neutro $\overrightarrow{OO}$, $V$ costituisce un gruppo commutativo. Per definizione di somma rispetto ad un gruppo commutativo, esiste un vettore opposto $-\overrightarrow{OA}$ tale che $-\overrightarrow{OA}+\overrightarrow{OA}=\overrightarrow{OO}.$ 

Aggiungiamo adesso un'operazione, la moltiplicazione per uno scalare $\lambda:\mathbb{R}\times V\longrightarrow V$ tale che $\lambda \overrightarrow{OA}\longrightarrow\lambda\cdot\overrightarrow{OA}.$ Per trovare il vettore risultante considero il segmento centrato in $O$ con la stessa direzione, stesso verso di $\overrightarrow{OA}$ se $\lambda>0$ (verso opposto nel caso in cui $\lambda<0$ e di lunghezza $\lambda\ell$ (con $\ell$ misura del segmento $\overrightarrow{OA}.$)

|                                   |                                      |
| --------------------------------- | ------------------------------------ |
| ![150](lez21prodottovettscal.svg) | ![180](lez21prodottovettscalneg.svg) |
| Caso in cui $\lambda>0$           | Caso in cui $\lambda<0$              | 

$V$ con queste 2 operazioni è uno spazio vettoriale su $\mathbb{R}$ denotato $\mathcal{V}_{O}^{2}.$

Analogamente, esiste $\mathcal{V}_{O}^{3}$ riferito all'insieme dei segmenti nello spazio euclideo orientati con il primo estremo in $O.$ 
#### Sottospazio Vettoriale
Sia $W\subseteq V$. $W$ viene definito sottospazio vettoriale se: 
1) $\forall\underline{w},\underline{w'},\qquad \underline{w}+\underline{w'}\in W.$
2) $\forall\lambda\in\mathbb{R},\forall \underline{w}\in W,\qquad\lambda \underline{w}\in W.$

Notiamo che $\underline{O}v\in W,$ perché per $\lambda=0$ $\forall w\in W, 0\cdot w \in W$ (e $\underline{O}v=0\cdot v$). Inoltre, $\forall\underline{w}\in W, -\underline{w}\in W$ (corrisponde a $\lambda\underline{w}$ con $\lambda=-1$).

Ciò implica che $W$ è anche sottogruppo di $(V,+),$ perché $\forall \underline{w_{1}},\underline{w_{2}}\in W$ si ha: $\underline{w_{1}}-\underline{w_{2}}=\underline{w_{1}}+(-1)\underline{w_{2}}.$ Ma $(-1)\underline{w_{2}}\in W$ e $\underline{w_{1}}+(-1)\underline{w_{2}}\in W.$

Osservazione: in $\mathcal{V}_{O}^{2},$ $W=\{\overrightarrow{OA}|A\in r_{0} \}$ (dove con $r_{0}$ è definita una retta appartenente a quel piano) è un sottospazio, e lo è anche $W=\{\overrightarrow{OA}|A\in \pi_{0} \}$ (dove $\pi_{0}$ rappresenta un piano appartenente a quello spazio) in $\mathcal{V}_{O}^{3}.$

### Combinazioni Lineari
Sia $V$ uno spazio vettoriale, la **combinazione lineare** di $k$ vettori $v_{1},...,v_{k}\in V$ con coefficienti $\alpha_{1},...,\alpha_{k}\in \mathbb{R}$ è il vettore $\alpha_{1}v_{1}+...+\alpha_{k}v_{k}\in V.$
#### Span di uno spazio vettoriale
Viene definito **Span** (sottospazio generato dai) vettori $v_{1},...,v_{k}$ è l'insieme di tutte le possibili combinazioni lineari di $v_{1},...,v_{k}.$ In simboli: $$Span(v_{1},...,v_{k})=\{\alpha_{1}v_{1}+...+\alpha_{k}v_{k}|a_{1},...,a_{k}\in\mathbb{R} \}.$$
Dimostrazione:
	Per dimostrare che è chiuso rispetto alla somma dobbiamo far vedere che la somma di due combinazioni lineari di $v_{1},...,v_{k}$ è ancora una combinazione lineare di $v_{1},...,v_{k}$. 
	Infatti se $\alpha_{1}v_{1}+...+\alpha_{k}v_{k}$ e $\beta_{1}v_{1}+...+\beta_{k}v_{k}$ sono due combinazioni lineari di $v_{1},...,v_{k},$ allora anche $$(\alpha_{1}v_{1}+...+\alpha_{k}v_{k})+(\beta_{1}v_{1}+...+\beta_{k}v_{k})=(\alpha_{1}+\beta_{k})v_{1}+...+(\alpha_{k}+b_{k})v_{k}$$è una combinazione lineare di $v_{1},...,v_{k}.$ Analogamente: $$\lambda(\alpha_{1}v_{1}+...+\alpha_{k}v_{k})=(\lambda\alpha_{1})v_{1}+...+(\lambda\alpha_{k})v_{k}$$è una combinazione lineare di $v_{1},...,v_{k}$ per ogni $\lambda.$ Quindi $Span(v_1,...v_{k})$ è un sottospazio.
###### Esempio - Span in $\mathbb{R}^{3}$
Prendiamo $V=\mathbb{R}^{3}$ e $v_{1}=\begin{vmatrix} 3\\1\\0 \end{vmatrix}$ e $v_{2}=\begin{vmatrix}-1\\-1\\0\end{vmatrix}.$ 
Allora:
$$Span(v_{1},v_{2})=\left\{ \alpha_{1}\begin{vmatrix}3\\1\\0 \end{vmatrix}+\alpha_{2}\begin{vmatrix}-1\\-1\\0 \end{vmatrix}\bigg |\alpha_{1},\alpha_{2}\in \mathbb{R} \right\}=\left\{\begin{vmatrix}3\alpha_{1}-\alpha_{2}\\ \alpha_{1}-\alpha_{2}\\0\end{vmatrix}\bigg|\alpha_{1},\alpha_{2}\in\mathbb{R} \right\}.$$
In questo caso, lo $Span(v_{1},v_{2})$ è il piano $z=0,$ ovvero tutti i vettori della forma $\begin{vmatrix} b_{1}\\b_{2}\\0.\end{vmatrix}.$ Infatti è facile verificare che per ogni $b_{1}, b_{2}\in \mathbb{R}$ esistono $\alpha_{1}, \alpha_{2}\in \mathbb{R}$ tali che$$\begin{cases} 3\alpha_{1}-\alpha_{2}=b_{1} \\
\alpha_{1}-\alpha_{2}=b_{2}\end{cases}\implies

\begin{cases} 3\alpha_{2}+3b_{2}-\alpha_{2}=b_{1}\\\alpha_{1}=\alpha_{2}+b_{2}\end{cases}\implies

\begin{cases}\alpha_{2}=\frac{b_{1}-3b_{2}}{2}\\\alpha_{1}=\frac{b_{1}-b_{2}}{2}\end{cases}$$per cui $$\begin{vmatrix} b_1\\b_{2}\\0\end{vmatrix}=\alpha_{1}v_{1}+\alpha_{2}v_{2}\in Span(v_{1},v_{2}).$$
###### Proposizione - Span delle colonne e risolubilità di un sistema
Sia $Ax=b$ un sistema lineare in $m$ equazioni ed $n$ incognite, e siano $A^{1},...,A^{n}\in\mathbb{R}^{m}$ le colonne della matrice dei coefficienti. Allora il sistema si definisce **compatibile** se e solo se $b\in Span(A^{1},...A^{n}).$

Dimostrazione:
	Il sistema può essere scritto come $x_{1}A^{1}+...+x_{n}A^{n}=b.$ Quindi il sistema è compatibile se e solo se $b$ è combinazione lineare delle colonne della matrice dei coefficienti, cioè se e solo se $b\in Span(A^{1},...,A^{n}).$ 
	(questo perché ogni equazione lineare può essere vista come una combinazione lineare delle colonne della matrice dei coefficienti, dove i coefficienti sono le soluzioni del sistema).

Quindi, quando abbiamo un sistema di equazioni $Ax=b$, stiamo cercando un vettore $x$ tale che la combinazione lineare delle colonne di $A$ dia il vettore $b$. Se tale vettore $x$ esiste, allora il sistema è compatibile. Se non esiste, allora il sistema non è compatibile.
###### Proposizione - Lo Span di $k$-vettori è un sottospazio vettoriale
Per dimostrare che lo Span di un insieme di $k$-vettori è un sottospazio vettoriale, dobbiamo verificare le tre proprietà fondamentali dei sottospazi vettoriali:
1. **Chiusura rispetto all'addizione**: Se $v$ e $w$ sono due vettori nello Span di un insieme di $k$-vettori, allora la loro somma $v + w$ è anche nello Span. Questo è vero perché $v$ e $w$ possono essere scritti come combinazioni lineari degli stessi $k$-vettori, e la somma di due combinazioni lineari degli stessi vettori è ancora una combinazione lineare di quei vettori.
2. **Chiusura rispetto alla moltiplicazione per scalari**: Se $v$ è un vettore nello Span di un insieme di k-vettori e $c$ è uno scalare, allora il prodotto $cv$ è anche nello Span. Questo è vero perché $v$ può essere scritto come una combinazione lineare di $k$-vettori, e moltiplicare una combinazione lineare per uno scalare produce ancora una combinazione lineare degli stessi vettori.
3. **Contiene il vettore nullo**: Lo Span di qualsiasi insieme di vettori contiene sempre il vettore nullo, poiché il vettore nullo può essere scritto come una combinazione lineare di $k$-vettori con tutti i coefficienti uguali a zero.
Quindi, lo Span di un insieme di k-vettori è un sottospazio vettoriale.


