 # Lezione 22
### Indipendenza Lineare e Basi
#### Dipendenza Lineare
Un insieme di vettori $v_{1},...,v_{k}\in V$ di uno spazio vettoriale $V$ si dice **linearmente dipendente** se esistono $\alpha_{1},...,\alpha_{k}\in\mathbb{R}$ non tutti nulli tali che $$\alpha_{1}v_{1}+...+\alpha_{k}v_{k}=O.\qquad (\star)$$Viceversa, $v_{1},...,v_{k}$ si dicono **linearmente indipendenti** se non sono linearmente dipendenti, ovvero se $\alpha_{1}v_{1}+...+\alpha_{k}v_{k}=O$ implica $\alpha_{1}=...=\alpha_{k}=O.$ L'equazione $(\star)$ si chiama *relazione di dipendenza lineare* fra $v_{1},...,v_{k}.$
###### Esempi - Vettori Linearmente Dipendenti 
1. Se fra i vettori $v_{1},...,v_{k}\in V$ vi è il vettore nullo, allora $v_{1},...,v_{k}$ sono linearmente dipendenti se $v_{i}=O$. Infatti, posso scrivere una combinazione lineare dove il coefficiente di $v_{i}$ è non nullo:$$0v_{1}+...+v_{i-1}+1v_{i}+0v_{i+1}+...+0v_{k}=O$$quindi vi è una relazione di dipendenza lineare fra $v_{1},...,v_{k}.$
2. Se fra i vettori $v_{1},...,v_{k}\in V$ ve ne sono  due uguali, allora $v_{1},...,v_{k}$ sono linearmente dipendenti. Infatti se si ha $v_{i}=v_{j}$ con $i<j$ posso scrivere una combinazione lineare in cui i coefficienti di $v_{i}$ e $v_{j}$ hanno segno opposto: $$0v_{1}+...+0v_{i-1}+v_{i}+0v_{i+1}+...+0v_{j-1}+(-1)v_{j}+0v_{j+1}+...+0v_{k}=O$$
3. Consideriamo i vettori: $$v_{1}=\begin{vmatrix}3\\1\\0 \end{vmatrix},\quad v_{2}=\begin{vmatrix}-1\\-1\\0\end{vmatrix},\quad v_{3}=\begin{vmatrix} 1\\0\\0\end{vmatrix}.$$Questi vettori sono linearmente dipendenti, infatti è possibile vedere che $v_{1}+v_{2}-2v_{3}=O.$
###### Esempio - Vettori Linearmente Indipendenti
Consideriamo i vettori: $$v_{1}=\begin{vmatrix}3\\1\\0\end{vmatrix}\quad e\quad v_{2}=\begin{vmatrix}-1\\-1\\0\end{vmatrix}.$$Questi vettori sono linearmente indipendenti, infatti la relazione $\alpha_{1}v_{1}+\alpha_{2}v_{2}=O$ vale se e solo se $$\begin{cases}(3)\alpha_{1}+(-1)\alpha_{2}=0&-\text{Confronto delle prime componenti dei vettori}\\(1)\alpha_{1}+(-1)\alpha_{2}=0&-\text{Confronto delle seconde componenti dei vettori}\\(0)\alpha_{1}+(0)\alpha_{2}=0&-\text{La terza componente non contribuisce al sistema.}\end{cases}$$ e questo sistema ha come unica soluzione $\alpha_{1}=\alpha_{2}=0.$
###### Osservazione - Vettore nullo implica dipendenza lineare
Se tra i vettori $\{\underline{v_{1}},\underline{v_{2}},...\underline{v_{n}} \}$ vi è un $v_{j}=\underline{0}\implies$ i vettori sono linearmente dipendenti.

Dimostrazione:
Se vi è un $v_{j}=0,$ avremo che $$0\cdot \underline{v_{1}}+0\cdot \underline{v_{2}} +0\cdot v_{j-1}+1\cdot \underset{0}{\underbrace{v_{j}}}+0\cdot v_{j+1}+0\cdot v_{n}$$
Ma $1\cdot 0=0,$ quindi ottengo $\underline{0}$ anche con coefficienti non tutti nulli $\implies$ i vettori sono linearmente dipendenti.
###### Osservazione - Vettori proporzionali e dipendenza lineare
I vettori $\{\underline{v_{1}},\underline{v_{2}},...\underline{v_{n}} \}$ sono linearmente dipendenti $\iff$ uno di essi è combinazione lineare degli altri.

Dimostrazione
$\implies:$
	Per ipotesi $\exists \alpha_{1},...,\alpha_{n}$ non tutti nulli, tali che $\alpha_{1}\underline{v_{1}}+...+\alpha_n\underline{v_{n}}=\underline{0}.$ Sia ad esempio $\alpha_{\ell}\ne0$ per qualche $\ell\in\{1,...,n \}.$ Quindi potremmo dividere tutto per $\alpha_{\ell}:$ $$\underline{v_{\ell}}=-\frac{\alpha_{1}}{\alpha_{\ell}}\cdot \underline{v_{1}}-\frac{\alpha_{2}}{\alpha_{\ell}}\cdot \underline{v_{2}}-...-\frac{\alpha_{n}}{\alpha_{\ell}}\cdot \underline{v_{n}}$$
$\Longleftarrow:$
	Se $\exists i$ tale che $\underline{v_{i}}=\beta\underline{v_{1}}+\beta\underline{v_{2}}+...+\beta_{i-1}\underline{v_{i-1}}+\beta_{n}\underline{v_{n}}.$ Se aggiungo $-\underline{v_{i}}$ ottengo $$0=-\underline{v_{i}}+ \beta\underline{v_{1}}+\beta\underline{v_{2}}+...+\beta_{i-1}\underline{v_{i-1}}+\beta_{n}\underline{v_{n}}.$$
	Il coefficiente di $v_{i}$ è $-1,$ ma il risultato della combinazione lineare è il vettore nullo, quindi sono linearmente dipendenti
#### Base di uno Spazio Vettoriale
Sia $V$ uno spazio vettoriale. Un insieme $\mathcal{B}=\{v_{1},...,v_{n} \}$ di vettori di $V$ è una base di $V$ se:
- $V=Span(v_{1},...,v_{n}),$ cioè $v_{1},...,v_{n}$ sono un *sistema di generatori* di $V$ )ovvero che  attraverso combinazioni lineari di questi vettori, è possibile ricostruire tutto lo spazio.
- $v_{1},...,v_{n}$ sono linearmente indipendenti.
###### Esempio - Base canonica di uno spazio vettoriale
I vettori $e_{1},...,e_{n}\in \mathbb{R}^{n},$ dove$$e_{1}=\begin{vmatrix} 1\\0\\ \vdots \\0 \end{vmatrix}, e_{2}=\begin{vmatrix} 0\\1\\ \vdots \\ 0\end{vmatrix},...,e_{n}=\begin{vmatrix} 0\\0\\\vdots\\1 \end{vmatrix},$$ sono una base di $\mathbb{R}^{n},$$$\begin{align} & \alpha_{1}\underline{e_{1}}+\alpha_{2}\underline{e_{2}}+...+\alpha_{n}\underline{e_{n}}=\underline{0} \implies \alpha_{1}\begin{vmatrix} 1\\0\\\vdots\\0\end{vmatrix} + \alpha_{2} \begin{vmatrix} 0\\1\\\vdots\\0 \end{vmatrix} +...+ \alpha_{n}\begin{vmatrix} 0\\0\\\vdots\\1\end{vmatrix} = \begin{vmatrix}0\\0\\\vdots\\0 \end{vmatrix}\\ & \implies \begin{vmatrix}\alpha_{1} \\ \alpha_{2} \\\vdots \\ \alpha_{n} \end{vmatrix}= \begin{vmatrix} 0\\0\\\vdots\\0 \end{vmatrix}\implies \text{vero solo se } \alpha_{j}=0\ \forall j.\end{align}$$
#### Esistenza delle Basi
##### Sottoinsieme massimale
Sia $A$ un sottoinsieme di uno spazio vettoriale $V.$ Diremo che **$\mathcal{B}\subseteq A$ è un sottoinsieme massimale in $A$** se gli elementi di $\mathcal{B}$ sono linearmente indipendenti e aggiungendo un qualunque altro elemento di $A$ si ottiene un insieme di vettori linearmente dipendenti.
###### Esempio - Sottoinsieme Massimale
Sia $V$ il sottospazio vettoriale, e $A$ suo sottoinsieme:$$V=\left\{\begin{vmatrix} b_{1}\\b_{2}\\0\end{vmatrix}\Bigg|b_{1},b_{2}\in\mathbb{R}\right\},\quad

A=\left\{v_{1}=\begin{vmatrix}3\\1\\0 \end{vmatrix},v_{2} = \begin{vmatrix}-1\\-1\\0\end{vmatrix},v_{3}= \begin{vmatrix} 2\\0\\0\end{vmatrix},e_{1}\right\}\subset V.$$
I vettori ${v_1,v_2}$ sono una base di $V.$ Infatti sono un sistema di generatori di $V,$ e tra loro sono [[#Esempio - Vettori Linearmente Indipendenti|linearmente indipendenti]].

Inoltre, $\mathcal{B}_{1} = {v_1,v_2}$ è un esempio (non l'unico) di sottoinsieme massimale in $A$ di vettori linearmente indipendenti, perché se provo ad aggiungere un altro elemento di $A$, i vettori diventano tra loro linearmente dipendenti.
###### Proposizione - Base come sottoinsieme massimale
Sia $\mathcal{B}=\{v_{1},...,v_{n}\}$ una base di uno spazio vettoriale $V.$ Allora $\mathcal{B}$ è un insieme massimale in $V$ di vettori linearmente indipendenti.

Dimostrazione:
	- Essendo $\mathcal{B}$ una base, i vettori $v_{1},...,v_{n}$ che la compongono sono linearmente indipendenti per definizione. Dobbiamo quindi dimostrare che preso un qualsiasi $w\in V,$ esso rende i vettori linearmente indipendenti.
	-  $\mathcal{B}$ è anche un sistema di generatori, per cui ogni elemento di $V$ (compreso $w$) potrà essere scritto come combinazione lineare degli elementi di $\mathcal{B}.$ In particolare $$w=\alpha_{1}v_{1}+...+\alpha_{n}v_{n}\implies w-\alpha_{1}v_{1}+...+\alpha_{n}v_{n}=O$$ che è proprio una relazione di dipendenza lineare tra $v_{1},...,v_{n}$ e $w$ (il suo coefficiente è $1$, non nullo).

Corollario: Ogni spazio vettoriale contenente un sistema finito di generatori ammette una base. 
#### Teorema del Completamento
Sia $\mathcal{B}=\{v_{1},...,v_{n}\}$ una base di uno spazio vettoriale $V$ e siano $w_{1},...,w_{p}\in V$ con vettori linearmente indipendenti, con $p\le n.$ Allora esistono $n-p$ vettori di $\mathcal{B}$ che insieme a $w_{1},...,w_{p}$ formano una base di $V$

Il professore ha omesso la dimostrazione (godo).

Se $w_{1},...,w_{p}$ sono vettori linearmente indipendenti di $\mathbb{R}^{n},$ per completarli a una base basta aggiungervi $n-p$ vettori della base canonica. Infatti, basta estrarre una base dall'insieme $\{w_{1},...,w_{p},e_{1},...e_{n}\}.$
###### Esempio - Utilizzo del teorema del completamento
Prendiamo i vettori $$w_{1}=\begin{vmatrix}1\\0\\1\\0\end{vmatrix},\quad w_{2}=\begin{vmatrix}1\\2\\3\\4, \end{vmatrix},\quad w_{1},w_{2}\in \mathbb{R}^{4};$$
Per dimostrare che sono linearmente indipendenti, risolviamo il sistema $\alpha_1w_1+\alpha_2w_2=O:$ $$\begin{cases}\alpha_{1}+\alpha_{2}=0,\\ 2\alpha_{2} = 0, \\ \alpha_{1} + 3\alpha_{2} =0, \\ 4\alpha_{1}=0,\end{cases}$$
Notiamo che l'unica soluzione accettabile è $\alpha_{1}=\alpha_{2}=0,$ per cui i vettori sono linearmente indipendenti. Per completare $\{w_{1},w_{2} \}$ a una base di $\mathbb{R}^4,$ scriviamo $w_{1}$ come combinazione dei vettori della base canonica di $\mathbb{R}^4:$ $$w_{1}=1e_{1}+0e_{2}+1e_{3}+0e_{4}. (\star \star) $$
La dimostrazione di questo teorema (anche se omessa, fidatevi e basta) ci dice che possiamo mettere $w_{1}$ al posto di uno qualunque dei vettori della base canonica che compaiono con coefficiente non nullo in $(\star\star)$ e ottenere ancora una base di $\mathbb{R}^4.$ 
Possiamo quindi scrivere $\mathcal{B}= \{w_{1},e_{2},e_{3},e_{4}\}.$ Eseguiamo il passaggio di prima anche con $w_{2}:$ $$w_{2}=1e_{1}+2e_{2}+3e_{3}+4e_{4}.$$
Come prima, possiamo mettere $w_{2}$ al posto di uno qualunque dei vettori (non $w_{1})$ della base canonica che compaiono con coefficiente non nullo. Sostituendo ad esempio con $e_{3},$ otteniamo $\{w_{1},w_{2},e_{2},e_{4}\}$ che completa $\{w_{1},w_{2}\}.$
###### Corollario - Stesso numero di elementi in basi di uno spazio vettoriale 
Due basi di uno spazio vettoriale $V$ hanno sempre lo stesso numero di elementi.

Dimostrazione:
Siano $\mathcal{B}=\{v_{1},...,v_{k}\}$ e $\mathcal{C}=\{w_{1},...,w_{h}\}$ due basi di $V$ e supponiamo per assurdo che $k>h.$ Allora il Teorema del completamento, applicato con $n=k$ e $p=h$ ci dice che esistono $k-h$ elementi di $\mathcal{B}$ che aggiunti a $\mathcal{C}$ formano una base. Ma $C$ era già una base, e quindi un insieme massimale di vettori linearmente indipendenti, il che è una contraddizione. Con lo stesso ragionamento notiamo che $h$ è maggiore di $k,$ concludiamo quindi che $k=h.$

Il numero di elementi di una base quindi è una caratteristica ben definita dello spazio vettoriale: la sua dimensione.
###### Definizione - Dimensione di uno spazio vettoriale
Se $\{v_{1},...,v_{n}\}$ è una base di uno spazio vettoriale $V,$ il numero $n$ (che per il Corollario visto ora non dipende dalla base scelta) si chiama **dimensione** di $V$ (scriviamo $n=\text{dimV}$ oppure $\text{dim}_{\mathbb{K}}V$ se bisogna specificare che sia uno spazio vettoriale nel campo $\mathbb{K}$). 
- Lo spazio vettoriale $\{ O\}$ composto solo dal vettore nullo ha dimensione zero
- Uno spazio vettoriale privo di sistemi di generatori finiti ha dimensione infinita

Per calcolare la dimensione di uno spazio vettoriale basta trovarne una base. Grazie alla base canonica ad esempio, sappiamo che $\mathbb{R}^n$ ha dimensione $n.$
# TODO
- dipendenza lineare; esempi ed osservazioni varie; 
- base di uno spazio vettoriale finitamente generato; esempi; 
- esistenza di una base (senza dimostrazione); 
- teorema del completamento (senza dimostrazione); 
- dimensione di uno spazio vettoriale